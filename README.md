# Warsztaty Badawcze - Grupa: Osobowość w sztucznej inteligencji: czy modele językowe potrzebują psychologii?

Zajęcia mają miejsce we wtorki **14.15-15.45**.

## Rozkład zajęć 
- 2025-02-25 - Prezentacja tematyki projektów
- 2025-03-04 - Zajęcie organizacyjne + [wprowadzenie do LLM-ów ](https://github.com/WiktoriaMK/PW_warsztaty_badawcze/blob/main/prezentacje/WB%20-%20LLMs%20wst%C4%99p.pdf)
- 2025-03-11 - Wprowadzenie teoretyczne do psychologii osobowości + omówienie artykułów 
- 2025-03-18 - Omówienie i dyskusja literatury - grupa 1,2,3 
- 2025-03-25 - Omówienie i dyskusja literatury - grupa 4,5
- 2025-04-01 - Dyskusja projektów 
- 2025-04-08 - Konsultacje projektów indywidualnych (on-line)
- 2025-04-15 - Przedstawienie postępów projektów  -> **Kamień milowy nr 1**
- 2025-04-29 - Konsultacje projektów indywidualnych (on-line) 
- 2025-05-06 - Konsultacje projektów indywidualnych (on-line)
- 2025-05-20 - Przedstawienie postępów projektów -> **Kamień milowy nr 2**
- 2025-05-27 - Konsultacje projektów indywidualnych
- 2025-06-03 - **Prezentacje** finalnych projektów
- 2025-06-10 - **Prezentacje** finalnych projektów

## Narzędzia
a) Promptowanie 
- https://www.together.ai/ 
- https://ollama.com/
- https://cloud.google.com/model-garden?hl=en 

## Ciekawe repozytoria
-https://github.com/kasperjunge/LLM-Guide 

## Prezentacje literatury

| lp | Tytuł artykułu | Grupa | Data prezentacji |
|----|--------------|-----------------|-----------------|
| 1  | [LLM Agents in Interaction: Measuring Personality Consistency and Linguistic Alignment in Interacting Populations of Large Language Models.](https://arxiv.org/abs/2402.02896 ) |  |  |
| 2  | [Self-assessment tests are unreliable measures of llm personality.](https://aclanthology.org/2024.blackboxnlp-1.20/) | Gimzicka, Kukla, Skwarek  | 25.03.2025 r. |
| 3  | [Do llms have distinct and consistent personality? TRAIT: Personality testset designed for llms with psychometrics.](https://arxiv.org/abs/2406.14703) |  |  |
| 4  | [The Dark Patterns of Personalized Persuasion in Large Language Models: Exposing Persuasive Linguistic Features for Big Five Personality Traits in LLMs Responses.](https://arxiv.org/abs/2411.06008) | Adamczyk, Cwalina, Iwaniuk | 18.03.2005 |
| 5  | [Limited Ability of LLMs to Simulate Human Psychological Behaviours: a Psychometric Analysis.](https://arxiv.org/abs/2405.07248) | Florek, Sobociński, Pozorski | 18.03.2025 |
| 6  | [Personality traits in large language models.](https://arxiv.org/abs/2307.00184) |  |  |
| 7  | [Resistance Against Manipulative AI: key factors and possible actions.](https://arxiv.org/abs/2404.14230) |  |  |
| 8  | [Can LLM "Self-report"?: Evaluating the Validity of Self-report Scales in Measuring Personality Design in LLM-based Chatbots.](https://arxiv.org/abs/2412.00207) |  |  |
| 9  | [The better angels of machine personality: How personality relates to llm safety.](https://arxiv.org/abs/2407.12344) |  |  |
| 10 | [Evaluating large language models in theory of mind tasks](https://arxiv.org/pdf/2302.02083) | Opala, Pytel, Rogalska | 25.03.2025 r. |

UWAGA: Trzy grupy powinny się zgłosić do prezentacji na 18 marca i dwie grupy na 25 marca.

### Artykuły do wyboru

| lp | Autorzy | Tytuł | Krótki opis |
|----|-------|-------|---------------|
| 1 |Frisch, I., & Giulianelli, M. (2024) | [LLM Agents in Interaction: Measuring Personality Consistency and Linguistic Alignment in Interacting Populations of Large Language Models.](https://arxiv.org/abs/2402.02896 )| Artykuł analizuje użycie języka w kontekście interakcji agentów LLM, mierząc spójnośćich osobowości. Bada, jak cechy osobowości wpływają na użycie języka w warunkach interaktywnych i nieinteraktywnych, wykorzystując do analiz kategorie LIWC (Linguistic Inquiry and Word Count). |
| 2 | Gupta, A., Song, X., & Anumanchipalli, G. (2024, November) | [Self-assessment tests are unreliable measures of llm personality. In Proceedings of the 7th BlackboxNLP Workshop: Analyzing and Interpreting Neural Networks for NLP (pp. 301-314)]( https://aclanthology.org/2024.blackboxnlp-1.20/) |Artykuł ten podważa wiarygodność testów samooceny w pomiarze osobowości LLM. Wykazuje, że wyniki testów w LLM nie są odporne na równoważne pytania i kolejność prezentowanych opcji. Badanie to analizuje wrażliwość na sformułowania pytań, porównując odpowiedzi modeli na trzy semantycznie równoważne pytania. |
| 3 | Lee, S., Lim, S., Han, S., Oh, G., Chae, H., Chung, J., ... & Yu, Y. (2024) | [Do llms have distinct and consistent personality? TRAIT: Personality testset designed for llms with psychometrics.](https://arxiv.org/abs/2406.14703) | Artykuł naukowy przedstawia TRAIT, nowy test psychometryczny stworzony do oceny osobowości dużych modeli językowych (LLM) w oparciu o popularne kwestionariusze ludzkie |
| 4 | Mieleszczenko-Kowszewicz, W., Płudowski, D., Kołodziejczyk, F., Świstak, J., Sienkiewicz, J., & Biecek, P. (2024) | [The Dark Patterns of Personalized Persuasion in Large Language Models: Exposing Persuasive Linguistic Features for Big Five Personality Traits in LLMs Responses.](https://arxiv.org/abs/2411.06008) | Artykuł bada, w jaki sposób LLM dostosowują swoje odpowiedzi w oparciu o osobowość użytkownika w zadaniu perswazji. Analizuje wzorce językowe używane przez modele w zależności od cech osobowości odbiorcy. W eksperymencie użyto różnorodnego zestawu 19 LLM i analizowano, jak modele te reagują na zmienne w zapytaniach perswazyjnych. |
| 5 | Petrov, N. B., Serapio-García, G., & Rentfrow, J. (2024) | [Limited Ability of LLMs to Simulate Human Psychological Behaviours: a Psychometric Analysis.](https://arxiv.org/abs/2405.07248) | Artykuł ten bada, czy duże modele językowe (LLM) są w stanie symulować ludzkie zachowania i osobowości. Wykorzystuje rygorystyczne metodologie psychometryczne do oceny, czy LLM mogą naśladować latentne konstrukty psychologiczne, które wpływają na zachowania w różnych zadaniach. Badacze użyli szablonu do zapytań, który zawierał instrukcję dotyczącą osobowości, opis persony, instrukcję testową, treść pytań. |
| 6 | Safdari, M., Serapio-García, G., Crepy, C., Fitz, S., Romero, P., Sun, L., Fitz, S., Romero, P., Abdulhai, M., Faust, A. & Matarić, M. (2023) | [Personality traits in large language models.](https://arxiv.org/abs/2307.00184) | Artykuł bada pomiar i kształtowanie osobowości w dużych modelach językowych (LLM). Sprawdza, czy LLM-y wiarygodnie symulują ludzką osobowość i czy można ją kształtować za pomocą strukturyzowanych podpowiedzi i testów osobowości. |
| 7 | Wilczyński, P., Mieleszczenko-Kowszewicz, W. & Biecek, P. (2024) | [Resistance Against Manipulative AI: key factors and possible actions. In: 27th European Conference on Artificial Intelligence. IOS Press.](https://arxiv.org/abs/2404.14230) | Artykuł "Resistance Against Manipulative AI" dotyczy problemu manipulacji ludźmi przez duże modele językowe (LLM). |
| 8 | Zou, H., Wang, P., Yan, Z., Sun, T., & Xiao, Z. (2024) | [Can LLM" Self-report"?: Evaluating the Validity of Self-report Scales in Measuring Personality Design in LLM-based Chatbots.](https://arxiv.org/abs/2412.00207) | Artykuł ten dotyczy badania, w jaki sposób można ocenić osobowość chatbotów z perspektywy człowieka, rekrutując uczestników do interakcji z chatbotami i wypełniania kwestionariuszy oceny osobowości oraz kwestionariuszy doświadczeń użytkownika. |
| 9 | Zhang, J., Liu, D., Qian, C., Gan, Z., Liu, Y., Qiao, Y., & Shao, J. (2024) | [The better angels of machine personality: How personality relates to llm safety.](https://arxiv.org/abs/2407.12344) |Artykuł analizuje, jak można kontrolować i edytować cechy osobowości w LLM, używając techniki wektorów sterujących. Bada, jak różne ustawienia, takie jak język i kolejność opcji, wpływają na ocenę MBTI (Myers-Briggs Type Indicator) dla LLM. W badaniu wykorzystano chińskie i angielskie wersje kwestionariusza MBTI-M, aby ocenić wyniki osobowości LLM w różnych kontekstach kulturowych. |
| 10 | Kosinski, M., (2024) | [Evaluating large language models in theory of mind tasks](https://arxiv.org/pdf/2302.02083) | Badanie teorii umysłu różnych LLMów | 

## Punktacja
max. 60 punktów:

1. 2 prace domowe : 4 pkt każda, łącznie max. 8 punktów 
2. Prezentacja literatury : 12 pkt 
3. Projekt :
   - Kamień milowy 1 -> 10 pkt
   - Kamień milowy 2 -> 20 pkt
   - Prezentacja projektu -> 10 pkt
  
Dodatkowe punkty mogą zostać przyznane za aktywność.

## Szczegóły dotyczące punktacji i wymagań na poszczególne deliverables
### Omówienie literatury (12 pkt)
- Ogólne streszczenie artykułu - 2 pkt
- Zastosowane metody - 2 pkt
- Przeprowadzone eksperymenty - 2  pkt
- Wyniki i wnioski - 2 pkt
- Limitations/ future works (na tej części powinien bazować poźniejszy plan badawczy projektu) - 3 pkt
- O autorach artykułu - 1 pkt
  
Czas na prezentację literatury: 20min prezentacja + 5min pytania
### Punktacja za KM1 (10 pkt)
- Przygotowanie opracowanego planu badawczego: 1-2 strony A4  (w sumie 8 pkt, podzielone jak poniżej)
   - Pytanie badawcze - 2 pkt
   - Jaki model/ jakie modele zostaną wykorzystane - 1.5 pkt
   - Jakie prompty zostaną wykorzystane - 1.5 pkt
   - Jakie koncepcje osobowości zostaną wykorzystane - 2 pkt
   - Podział pracy między członków zespołu - 1 pkt
- Założenie repozytorium zespołu i udostępnienie prowadzącym (niezbędne do zaliczenia KM1)
- Zaprezentowanie planu badawczego podczas zajęć 15.04: 10-15 min na zespół (zostanie udostępniony formularz do zapisania się, w jakiej kolejności grupy będą prezentować; wtedy też podamy dokładną długość prezentacji - będzie zależeć od liczby grup) -> 2 pkt
### Punktacja za KM2 (20 pkt)
- Przygotowanie podsumowania prac: 4-6 stron A4 dokumentu lub Jupyter Notebook zawierającego (w sumie 13 pkt, podzielone jak poniżej):
   - Opis co zostało wykonane w ramach projektu (cel badawczy, wykorzystane modele, cele i krótkie opisy eksperymentów) -> 3 pkt
   - Rezultaty osiągnięte podczas eksperymentów -> 3 pkt
   - Dyskusja: co wyszło, co nie, jakie problemy pojawiły się podczas pracy nad projektem -> 3 pkt
   - Future works, potencjalne zastosowanie w biznesie, plan pracy na ostatnie kilka tygodni pracy nad projektem, podział pracy między członków zespołu -> 1pkt
   - Uzasadnienie merytoryczne dlaczego taki cel badawczy został wybrany, dlaczego takie a nie inne metody i narzędzia zostały użyte, a eksperymenty przeprowadzone -> 3 pkt
- Zaprezentowanie dotychczasowych efektów pracy podczas zajęć 20.05: 10-15min na zespół (zostanie udostępniony formularz do zapisania się, w jakiej kolejności grupy będą prezentować; wtedy też podamy dokładną długość prezentacji - będzie zależeć od liczby grup) -> 2 pkt
- Udostępnienie kodu na repozytorium zespołu odzwierciedlającego opisywane eksperymenty i ich wyniki -> 5 pkt
   - Wszystkie materiały dostarczone na repozytorium powinny pozwalać na bezproblemowe uruchomienie przestawionych eksperymentów oraz zreprodukowanie wyników
### Punktacja za prezentację (10 pkt)
- Wprowadzenie teoretyczne, cel, pytanie badawcze - 2 pkt
- Zastosowane metody - 2 pkt
- Opis eksperymentów - 1 pkt
- Wyniki i wnioski - 2 pkt
- Future works, potencjalne zastosowanie w biznesie - 2 pkt
- Czytelność slajdów, poprawność wizualizacji - 1 pkt
  
## Komunikacja

Slack, USOS

## Projekty

Opis dokładnych deliverables na poszczególne kamienie milowe - jak wyżej.

# Punktacja za omówienie literatury (12 pkt)
Ogólne streszczenie artykułu - 2 pkt
Zastosowane metody - 2 pkt
Przeprowadzone eksperymenty - 2  pkt
Wyniki i wnioski - 2 pkt
Limitations/ future works (na tym bazujemy plan badawczy do projektu) - 3 pkt
O autorach i ich backgroundzie - 1 pkt
Czas na prezentację literatury: 20min prezentacja + 5min pytania
# Punktacja za KM1 (10 pkt)
Opracowanie planu badawczego: 1-2 strony A4  (w sumie 8 pkt, podzielone jak poniżej)
Pytanie badawcze - 2 pkt
Opis wykorzystanych modeli - 1.5 pkt
Opis promptów - 1.5 pkt
Opis koncepcji osobowości - 2 pkt
Podział pracy między członków zespołu - 1 pkt
założenie repozytorium zespołu i udostępnienie prowadzącym (niezbędne do zaliczenia KM1)
zaprezentowanie planu badawczego podczas zajęć 15.04: 10-15min na zespół - 2 pkt

